128
==PROF== Connected to process 27098 (/zhome/14/5/127713/Documents/HPC/assignment3/poisson/poisson_v2/example3d)
==PROF== Profiling "_Z23d_malloc_3d_gpu_kernel1PP..." - 1: 0%....50%....100% - 10 passes
==PROF== Profiling "_Z23d_malloc_3d_gpu_kernel2PP..." - 2: 0%....50%....100% - 10 passes
==PROF== Profiling "_Z23d_malloc_3d_gpu_kernel1PP..." - 3: 0%....50%....100% - 10 passes
==PROF== Profiling "_Z23d_malloc_3d_gpu_kernel2PP..." - 4: 0%....50%....100% - 10 passes
==PROF== Profiling "_Z23d_malloc_3d_gpu_kernel1PP..." - 5: 0%....50%....100% - 10 passes
==PROF== Profiling "_Z23d_malloc_3d_gpu_kernel2PP..." - 6: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 7: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 8: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 9: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 10: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 11: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 12: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 13: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 14: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 15: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 16: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 17: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 18: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 19: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 20: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 21: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 22: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 23: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 24: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 25: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 26: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 27: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 28: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 29: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 30: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 31: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 32: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 33: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 34: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 35: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 36: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 37: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 38: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 39: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 40: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 41: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 42: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 43: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 44: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 45: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 46: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 47: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 48: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 49: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 50: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 51: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 52: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 53: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 54: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 55: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 56: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 57: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 58: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 59: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 60: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 61: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 62: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 63: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 64: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 65: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 66: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 67: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 68: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 69: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 70: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 71: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 72: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 73: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 74: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 75: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 76: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 77: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 78: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 79: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 80: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 81: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 82: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 83: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 84: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 85: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 86: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 87: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 88: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 89: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 90: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 91: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 92: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 93: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 94: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 95: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 96: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 97: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 98: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 99: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 100: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 101: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 102: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 103: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 104: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 105: 0%....50%....100% - 10 passes
==PROF== Profiling "jacobi" - 106: 0%....50%....100% - 10 passes
128 31.309945
==PROF== Disconnected from process 27098
[27098] example3d@127.0.0.1
  _Z23d_malloc_3d_gpu_kernel1PPPdiii, 2022-Jan-20 21:10:36, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         970.20
    SM Frequency                                                             cycle/usecond                         610.39
    Elapsed Cycles                                                                   cycle                           2951
    Memory [%]                                                                           %                           0.78
    DRAM Throughput                                                                      %                           0.00
    Duration                                                                       usecond                           4.83
    L1/TEX Cache Throughput                                                              %                           6.56
    L2 Cache Throughput                                                                  %                           0.78
    SM Active Cycles                                                                 cycle                          65.52
    Compute (SM) [%]                                                                     %                           0.01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         16
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32.77
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0.00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                            128
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                             64
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                           1.56
    Achieved Active Warps Per SM                                                      warp                              1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM The     
          difference between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  _Z23d_malloc_3d_gpu_kernel2PPPdiii, 2022-Jan-20 21:10:37, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         925.13
    SM Frequency                                                             cycle/usecond                         583.63
    Elapsed Cycles                                                                   cycle                           3643
    Memory [%]                                                                           %                           4.69
    DRAM Throughput                                                                      %                           0.02
    Duration                                                                       usecond                           6.24
    L1/TEX Cache Throughput                                                              %                          19.02
    L2 Cache Throughput                                                                  %                           3.04
    SM Active Cycles                                                                 cycle                         897.13
    Compute (SM) [%]                                                                     %                           0.91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32.77
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          16384
    Waves Per SM                                                                                                     0.07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11.63
    Achieved Active Warps Per SM                                                      warp                           7.44
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (11.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  _Z23d_malloc_3d_gpu_kernel1PPPdiii, 2022-Jan-20 21:10:37, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         976.16
    SM Frequency                                                             cycle/usecond                         614.80
    Elapsed Cycles                                                                   cycle                           2972
    Memory [%]                                                                           %                           0.78
    DRAM Throughput                                                                      %                           0.00
    Duration                                                                       usecond                           4.83
    L1/TEX Cache Throughput                                                              %                           6.53
    L2 Cache Throughput                                                                  %                           0.78
    SM Active Cycles                                                                 cycle                          65.75
    Compute (SM) [%]                                                                     %                           0.01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         16
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32.77
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0.00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                            128
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                             64
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                           1.56
    Achieved Active Warps Per SM                                                      warp                           1.00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM The     
          difference between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  _Z23d_malloc_3d_gpu_kernel2PPPdiii, 2022-Jan-20 21:10:37, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         921.83
    SM Frequency                                                             cycle/usecond                         581.26
    Elapsed Cycles                                                                   cycle                           3665
    Memory [%]                                                                           %                           4.66
    DRAM Throughput                                                                      %                           0.02
    Duration                                                                       usecond                           6.30
    L1/TEX Cache Throughput                                                              %                          18.78
    L2 Cache Throughput                                                                  %                           3.03
    SM Active Cycles                                                                 cycle                         908.57
    Compute (SM) [%]                                                                     %                           0.91
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32.77
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          16384
    Waves Per SM                                                                                                     0.07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11.64
    Achieved Active Warps Per SM                                                      warp                           7.45
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (11.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  _Z23d_malloc_3d_gpu_kernel1PPPdiii, 2022-Jan-20 21:10:37, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         967.74
    SM Frequency                                                             cycle/usecond                         609.04
    Elapsed Cycles                                                                   cycle                           3022
    Memory [%]                                                                           %                           0.76
    DRAM Throughput                                                                      %                           0.00
    Duration                                                                       usecond                           4.96
    L1/TEX Cache Throughput                                                              %                           6.56
    L2 Cache Throughput                                                                  %                           0.76
    SM Active Cycles                                                                 cycle                          65.52
    Compute (SM) [%]                                                                     %                           0.01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.0 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                         16
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                           8
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32.77
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                            128
    Waves Per SM                                                                                                     0.00
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   Threads are executed in groups of 32 threads called warps. This kernel launch is configured to execute 16     
          threads per block. Consequently, some threads in a warp are masked off and those hardware resources are       
          unused. Try changing the number of threads per block to be a multiple of 32 threads. Between 128 and 256      
          threads per block is a good initial range for experimentation. Use smaller thread blocks rather than one      
          large thread block per multiprocessor if latency affects performance.  This is particularly beneficial to     
          kernels that frequently call __syncthreads(). See the Hardware Model                                          
          (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model) description for more      
          details on launch configurations.                                                                             
    ----- --------------------------------------------------------------------------------------------------------------
    WRN   The grid for this launch is configured to execute only 8 blocks, which is less than the GPU's 108             
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                            128
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                             64
    Theoretical Active Warps per SM                                                   warp                             32
    Theoretical Occupancy                                                                %                             50
    Achieved Occupancy                                                                   %                           1.56
    Achieved Active Warps Per SM                                                      warp                              1
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy (50.0%) is limited by the number of blocks that can fit on the SM The     
          difference between calculated theoretical (50.0%) and measured achieved occupancy (1.6%) can be the result    
          of warp scheduling overheads or workload imbalances during the kernel execution. Load imbalances can occur    
          between warps within a block as well as across blocks of the same kernel. See the CUDA Best Practices Guide   
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  _Z23d_malloc_3d_gpu_kernel2PPPdiii, 2022-Jan-20 21:10:38, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/usecond                         933.33
    SM Frequency                                                             cycle/usecond                         587.30
    Elapsed Cycles                                                                   cycle                           3722
    Memory [%]                                                                           %                           4.59
    DRAM Throughput                                                                      %                           0.02
    Duration                                                                       usecond                           6.34
    L1/TEX Cache Throughput                                                              %                          18.92
    L2 Cache Throughput                                                                  %                           2.94
    SM Active Cycles                                                                 cycle                         901.86
    Compute (SM) [%]                                                                     %                           0.89
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel grid is too small to fill the available resources on this device, resulting in only 0.1 full      
          waves across all SMs. Look at Launch Statistics for more details.                                             

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        256
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                          64
    Registers Per Thread                                                   register/thread                             16
    Shared Memory Configuration Size                                                 Kbyte                          32.77
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                          16384
    Waves Per SM                                                                                                     0.07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   The grid for this launch is configured to execute only 64 blocks, which is less than the GPU's 108            
          multiprocessors. This can underutilize some multiprocessors. If you do not intend to execute this kernel      
          concurrently with other workloads, consider reducing the block size to have at least one block per            
          multiprocessor or increase the size of the grid to fully utilize the available hardware resources. See the    
          Hardware Model (https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#metrics-hw-model)            
          description for more details on launch configurations.                                                        

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                             16
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              8
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          11.63
    Achieved Active Warps Per SM                                                      warp                           7.45
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (11.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:38, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.17
    Elapsed Cycles                                                                   cycle                         242435
    Memory [%]                                                                           %                          92.98
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.91
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.64
    SM Active Cycles                                                                 cycle                      237119.58
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.12
    Achieved Active Warps Per SM                                                      warp                          55.12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:38, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.52
    Elapsed Cycles                                                                   cycle                         242963
    Memory [%]                                                                           %                          92.80
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.62
    L1/TEX Cache Throughput                                                              %                          95.20
    L2 Cache Throughput                                                                  %                          32.63
    SM Active Cycles                                                                 cycle                      236844.50
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.38
    Achieved Active Warps Per SM                                                      warp                          55.28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:39, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.87
    Elapsed Cycles                                                                   cycle                         243175
    Memory [%]                                                                           %                          92.68
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.75
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.63
    SM Active Cycles                                                                 cycle                      237099.77
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.56
    Achieved Active Warps Per SM                                                      warp                          55.40
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:39, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.24
    Elapsed Cycles                                                                   cycle                         243072
    Memory [%]                                                                           %                          92.74
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.05
    L1/TEX Cache Throughput                                                              %                          95.13
    L2 Cache Throughput                                                                  %                          32.65
    SM Active Cycles                                                                 cycle                      236963.33
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.19
    Achieved Active Warps Per SM                                                      warp                          55.16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:39, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.63
    Elapsed Cycles                                                                   cycle                         242750
    Memory [%]                                                                           %                          92.86
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         319.55
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.68
    SM Active Cycles                                                                 cycle                      237109.46
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.38
    Achieved Active Warps Per SM                                                      warp                          55.28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:40, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.94
    Elapsed Cycles                                                                   cycle                         242509
    Memory [%]                                                                           %                          92.95
    DRAM Throughput                                                                      %                           8.58
    Duration                                                                       usecond                         318.69
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.70
    SM Active Cycles                                                                 cycle                      236894.36
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.06
    Achieved Active Warps Per SM                                                      warp                          55.08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:40, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.01
    Elapsed Cycles                                                                   cycle                         243017
    Memory [%]                                                                           %                          92.75
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.74
    L1/TEX Cache Throughput                                                              %                          95.02
    L2 Cache Throughput                                                                  %                          32.53
    SM Active Cycles                                                                 cycle                      237195.69
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.12
    Achieved Active Warps Per SM                                                      warp                          55.12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:40, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.95
    Elapsed Cycles                                                                   cycle                         242905
    Memory [%]                                                                           %                          92.82
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.37
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.62
    SM Active Cycles                                                                 cycle                      236900.48
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.57
    Achieved Active Warps Per SM                                                      warp                          55.40
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:40, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.39
    Elapsed Cycles                                                                   cycle                         243537
    Memory [%]                                                                           %                          92.55
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         318.59
    L1/TEX Cache Throughput                                                              %                          95.09
    L2 Cache Throughput                                                                  %                          32.45
    SM Active Cycles                                                                 cycle                      237009.10
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.18
    Achieved Active Warps Per SM                                                      warp                          55.16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:41, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.84
    Elapsed Cycles                                                                   cycle                         242722
    Memory [%]                                                                           %                          92.88
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         319.01
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.66
    SM Active Cycles                                                                 cycle                      236909.79
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.80
    Achieved Active Warps Per SM                                                      warp                          55.55
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:41, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.02
    Elapsed Cycles                                                                   cycle                         243050
    Memory [%]                                                                           %                          92.73
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.94
    L1/TEX Cache Throughput                                                              %                          95.02
    L2 Cache Throughput                                                                  %                          32.46
    SM Active Cycles                                                                 cycle                      237179.59
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.38
    Achieved Active Warps Per SM                                                      warp                          55.28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:41, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.16
    Elapsed Cycles                                                                   cycle                         242974
    Memory [%]                                                                           %                          92.78
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.37
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.66
    SM Active Cycles                                                                 cycle                      236885.93
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.00
    Achieved Active Warps Per SM                                                      warp                          55.04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:42, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.86
    Elapsed Cycles                                                                   cycle                         242851
    Memory [%]                                                                           %                          92.82
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.75
    L1/TEX Cache Throughput                                                              %                          95.04
    L2 Cache Throughput                                                                  %                          32.55
    SM Active Cycles                                                                 cycle                      237171.20
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.40
    Achieved Active Warps Per SM                                                      warp                          55.29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:42, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.87
    Elapsed Cycles                                                                   cycle                         242802
    Memory [%]                                                                           %                          92.85
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         319.10
    L1/TEX Cache Throughput                                                              %                          95.11
    L2 Cache Throughput                                                                  %                          32.62
    SM Active Cycles                                                                 cycle                      237026.56
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.15
    Achieved Active Warps Per SM                                                      warp                          55.14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:42, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.66
    Elapsed Cycles                                                                   cycle                         242958
    Memory [%]                                                                           %                          92.78
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.98
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.65
    SM Active Cycles                                                                 cycle                      237145.14
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.12
    Achieved Active Warps Per SM                                                      warp                          55.12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:43, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.56
    Elapsed Cycles                                                                   cycle                         242462
    Memory [%]                                                                           %                          92.99
    DRAM Throughput                                                                      %                           8.59
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.18
    L2 Cache Throughput                                                                  %                          32.63
    SM Active Cycles                                                                 cycle                      236879.86
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.53
    Achieved Active Warps Per SM                                                      warp                          55.38
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:43, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.59
    Elapsed Cycles                                                                   cycle                         243439
    Memory [%]                                                                           %                          92.59
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         320.48
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.46
    SM Active Cycles                                                                 cycle                      237119.36
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.57
    Achieved Active Warps Per SM                                                      warp                          55.41
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:43, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.86
    Elapsed Cycles                                                                   cycle                         242610
    Memory [%]                                                                           %                          92.92
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.43
    L1/TEX Cache Throughput                                                              %                          95.14
    L2 Cache Throughput                                                                  %                          32.54
    SM Active Cycles                                                                 cycle                      236933.20
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.51
    Achieved Active Warps Per SM                                                      warp                          55.36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:43, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.49
    Elapsed Cycles                                                                   cycle                         243218
    Memory [%]                                                                           %                          92.68
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.81
    L1/TEX Cache Throughput                                                              %                          95.01
    L2 Cache Throughput                                                                  %                          32.67
    SM Active Cycles                                                                 cycle                      237246.85
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.21
    Achieved Active Warps Per SM                                                      warp                          55.17
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:44, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.72
    Elapsed Cycles                                                                   cycle                         242953
    Memory [%]                                                                           %                          92.79
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         319.36
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.57
    SM Active Cycles                                                                 cycle                      236858.18
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.38
    Achieved Active Warps Per SM                                                      warp                          55.28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:44, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.27
    Elapsed Cycles                                                                   cycle                         243398
    Memory [%]                                                                           %                          92.62
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.30
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                      237107.96
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.07
    Achieved Active Warps Per SM                                                      warp                          55.08
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:44, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         765.27
    Elapsed Cycles                                                                   cycle                         243596
    Memory [%]                                                                           %                          92.54
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         318.30
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.56
    SM Active Cycles                                                                 cycle                      236877.82
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.27
    Achieved Active Warps Per SM                                                      warp                          55.21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:45, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.96
    Elapsed Cycles                                                                   cycle                         243669
    Memory [%]                                                                           %                          92.51
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         318.94
    L1/TEX Cache Throughput                                                              %                          95.03
    L2 Cache Throughput                                                                  %                          32.51
    SM Active Cycles                                                                 cycle                      237194.98
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.42
    Achieved Active Warps Per SM                                                      warp                          55.31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:45, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.92
    Elapsed Cycles                                                                   cycle                         243531
    Memory [%]                                                                           %                          92.57
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.12
    L2 Cache Throughput                                                                  %                          32.51
    SM Active Cycles                                                                 cycle                      237007.42
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.27
    Achieved Active Warps Per SM                                                      warp                          55.21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:45, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.92
    Elapsed Cycles                                                                   cycle                         243482
    Memory [%]                                                                           %                          92.57
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         319.55
    L1/TEX Cache Throughput                                                              %                          95.02
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                      237207.83
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.25
    Achieved Active Warps Per SM                                                      warp                          55.20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:46, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.48
    Elapsed Cycles                                                                   cycle                         242978
    Memory [%]                                                                           %                          92.78
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.66
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.56
    SM Active Cycles                                                                 cycle                      236914.31
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.69
    Achieved Active Warps Per SM                                                      warp                          55.48
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.7%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:46, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.26
    Elapsed Cycles                                                                   cycle                         243125
    Memory [%]                                                                           %                          92.72
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.36
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.51
    SM Active Cycles                                                                 cycle                      237129.99
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.04
    Achieved Active Warps Per SM                                                      warp                          55.07
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:46, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.78
    Elapsed Cycles                                                                   cycle                         242508
    Memory [%]                                                                           %                          92.98
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         319.17
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.72
    SM Active Cycles                                                                 cycle                      236932.81
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.24
    Achieved Active Warps Per SM                                                      warp                          55.19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:46, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.91
    Elapsed Cycles                                                                   cycle                         242844
    Memory [%]                                                                           %                          92.81
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.72
    L1/TEX Cache Throughput                                                              %                          95.04
    L2 Cache Throughput                                                                  %                          32.59
    SM Active Cycles                                                                 cycle                      237140.45
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.31
    Achieved Active Warps Per SM                                                      warp                          55.24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:47, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.59
    Elapsed Cycles                                                                   cycle                         243081
    Memory [%]                                                                           %                          92.74
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.75
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.55
    SM Active Cycles                                                                 cycle                      236916.95
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.83
    Achieved Active Warps Per SM                                                      warp                          54.93
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (85.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:47, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.02
    Elapsed Cycles                                                                   cycle                         243759
    Memory [%]                                                                           %                          92.47
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         319.46
    L1/TEX Cache Throughput                                                              %                          95.01
    L2 Cache Throughput                                                                  %                          32.53
    SM Active Cycles                                                                 cycle                      237229.07
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.93
    Achieved Active Warps Per SM                                                      warp                          54.99
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (85.9%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:47, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.80
    Elapsed Cycles                                                                   cycle                         243024
    Memory [%]                                                                           %                          92.76
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.18
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.57
    SM Active Cycles                                                                 cycle                      236935.32
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.69
    Achieved Active Warps Per SM                                                      warp                          55.48
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.7%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:48, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.68
    Elapsed Cycles                                                                   cycle                         243158
    Memory [%]                                                                           %                          92.70
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.65
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                         237083
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.96
    Achieved Active Warps Per SM                                                      warp                          55.02
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:48, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.18
    Elapsed Cycles                                                                   cycle                         243416
    Memory [%]                                                                           %                          92.63
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.53
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.53
    SM Active Cycles                                                                 cycle                      236899.04
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.29
    Achieved Active Warps Per SM                                                      warp                          55.23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:48, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.02
    Elapsed Cycles                                                                   cycle                         243222
    Memory [%]                                                                           %                          92.68
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.17
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.64
    SM Active Cycles                                                                 cycle                      237165.08
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.12
    Achieved Active Warps Per SM                                                      warp                          55.12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:49, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.54
    Elapsed Cycles                                                                   cycle                         243386
    Memory [%]                                                                           %                          92.63
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.17
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.52
    SM Active Cycles                                                                 cycle                      236921.19
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.51
    Achieved Active Warps Per SM                                                      warp                          55.36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:49, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.58
    Elapsed Cycles                                                                   cycle                         242909
    Memory [%]                                                                           %                          92.79
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.53
    L1/TEX Cache Throughput                                                              %                          95.08
    L2 Cache Throughput                                                                  %                          32.57
    SM Active Cycles                                                                 cycle                      237066.59
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.23
    Achieved Active Warps Per SM                                                      warp                          55.19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:49, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.51
    Elapsed Cycles                                                                   cycle                         242912
    Memory [%]                                                                           %                          92.80
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.98
    L1/TEX Cache Throughput                                                              %                          95.20
    L2 Cache Throughput                                                                  %                          32.62
    SM Active Cycles                                                                 cycle                      236789.04
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.16
    Achieved Active Warps Per SM                                                      warp                          55.14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:49, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.05
    Elapsed Cycles                                                                   cycle                         242273
    Memory [%]                                                                           %                          93.04
    DRAM Throughput                                                                      %                           8.59
    Duration                                                                       usecond                         318.75
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.73
    SM Active Cycles                                                                 cycle                      237091.10
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.26
    Achieved Active Warps Per SM                                                      warp                          55.20
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:50, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         758.99
    Elapsed Cycles                                                                   cycle                         242202
    Memory [%]                                                                           %                          93.06
    DRAM Throughput                                                                      %                           8.59
    Duration                                                                       usecond                         319.10
    L1/TEX Cache Throughput                                                              %                          95.19
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                      236772.32
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.35
    Achieved Active Warps Per SM                                                      warp                          55.26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:50, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.13
    Elapsed Cycles                                                                   cycle                         243665
    Memory [%]                                                                           %                          92.51
    DRAM Throughput                                                                      %                          10.85
    Duration                                                                       usecond                         319.71
    L1/TEX Cache Throughput                                                              %                          95.08
    L2 Cache Throughput                                                                  %                          32.44
    SM Active Cycles                                                                 cycle                      237070.26
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.04
    Achieved Active Warps Per SM                                                      warp                          55.06
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:51, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.20
    SM Frequency                                                             cycle/usecond                         758.27
    Elapsed Cycles                                                                   cycle                         242505
    Memory [%]                                                                           %                          92.96
    DRAM Throughput                                                                      %                          12.38
    Duration                                                                       usecond                         319.81
    L1/TEX Cache Throughput                                                              %                          95.10
    L2 Cache Throughput                                                                  %                          32.55
    SM Active Cycles                                                                 cycle                      237035.94
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.19
    Achieved Active Warps Per SM                                                      warp                          55.16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:51, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.83
    Elapsed Cycles                                                                   cycle                         243087
    Memory [%]                                                                           %                          92.73
    DRAM Throughput                                                                      %                          12.27
    Duration                                                                       usecond                         318.66
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.52
    SM Active Cycles                                                                 cycle                      237120.58
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.30
    Achieved Active Warps Per SM                                                      warp                          55.23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:52, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.21
    Elapsed Cycles                                                                   cycle                         242691
    Memory [%]                                                                           %                          92.90
    DRAM Throughput                                                                      %                          12.38
    Duration                                                                       usecond                         318.40
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.52
    SM Active Cycles                                                                 cycle                      236905.63
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.39
    Achieved Active Warps Per SM                                                      warp                          55.29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:52, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.55
    Elapsed Cycles                                                                   cycle                         243601
    Memory [%]                                                                           %                          92.53
    DRAM Throughput                                                                      %                          12.35
    Duration                                                                       usecond                         319.87
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.36
    SM Active Cycles                                                                 cycle                      237118.03
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.84
    Achieved Active Warps Per SM                                                      warp                          55.58
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:53, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.69
    Elapsed Cycles                                                                   cycle                         243165
    Memory [%]                                                                           %                          92.72
    DRAM Throughput                                                                      %                          12.16
    Duration                                                                       usecond                         319.23
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.49
    SM Active Cycles                                                                 cycle                      236893.25
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.31
    Achieved Active Warps Per SM                                                      warp                          55.24
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:53, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.45
    Elapsed Cycles                                                                   cycle                         242764
    Memory [%]                                                                           %                          92.85
    DRAM Throughput                                                                      %                          12.41
    Duration                                                                       usecond                         319.23
    L1/TEX Cache Throughput                                                              %                          95.11
    L2 Cache Throughput                                                                  %                          32.60
    SM Active Cycles                                                                 cycle                      237009.38
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.39
    Achieved Active Warps Per SM                                                      warp                          55.29
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:54, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.68
    Elapsed Cycles                                                                   cycle                         242716
    Memory [%]                                                                           %                          92.88
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         319.07
    L1/TEX Cache Throughput                                                              %                          95.13
    L2 Cache Throughput                                                                  %                          32.41
    SM Active Cycles                                                                 cycle                      236968.70
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.49
    Achieved Active Warps Per SM                                                      warp                          55.35
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:54, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.99
    Elapsed Cycles                                                                   cycle                         243311
    Memory [%]                                                                           %                          92.66
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         318.88
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.56
    SM Active Cycles                                                                 cycle                      237179.17
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.13
    Achieved Active Warps Per SM                                                      warp                          55.12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:54, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.83
    Elapsed Cycles                                                                   cycle                         242057
    Memory [%]                                                                           %                          93.13
    DRAM Throughput                                                                      %                           8.60
    Duration                                                                       usecond                         318.56
    L1/TEX Cache Throughput                                                              %                          95.18
    L2 Cache Throughput                                                                  %                          32.65
    SM Active Cycles                                                                 cycle                      236831.69
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.46
    Achieved Active Warps Per SM                                                      warp                          55.33
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:54, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.70
    Elapsed Cycles                                                                   cycle                         243243
    Memory [%]                                                                           %                          92.67
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         318.08
    L1/TEX Cache Throughput                                                              %                          95.09
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                      237050.36
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.86
    Achieved Active Warps Per SM                                                      warp                          54.95
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (85.9%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:55, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.86
    Elapsed Cycles                                                                   cycle                         242851
    Memory [%]                                                                           %                          92.82
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.75
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.58
    SM Active Cycles                                                                 cycle                      236860.97
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.48
    Achieved Active Warps Per SM                                                      warp                          55.34
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:55, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         765.23
    Elapsed Cycles                                                                   cycle                         243728
    Memory [%]                                                                           %                          92.48
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         318.50
    L1/TEX Cache Throughput                                                              %                          95.04
    L2 Cache Throughput                                                                  %                          32.45
    SM Active Cycles                                                                 cycle                      237157.45
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.29
    Achieved Active Warps Per SM                                                      warp                          55.23
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:55, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.58
    Elapsed Cycles                                                                   cycle                         243422
    Memory [%]                                                                           %                          92.62
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         318.78
    L1/TEX Cache Throughput                                                              %                          95.13
    L2 Cache Throughput                                                                  %                          32.39
    SM Active Cycles                                                                 cycle                      236987.76
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.96
    Achieved Active Warps Per SM                                                      warp                          55.01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:56, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.36
    Elapsed Cycles                                                                   cycle                         243478
    Memory [%]                                                                           %                          92.56
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         318.53
    L1/TEX Cache Throughput                                                              %                          95.02
    L2 Cache Throughput                                                                  %                          32.55
    SM Active Cycles                                                                 cycle                      237166.27
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.37
    Achieved Active Warps Per SM                                                      warp                          55.28
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:56, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.31
    Elapsed Cycles                                                                   cycle                         243407
    Memory [%]                                                                           %                          92.62
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.71
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.63
    SM Active Cycles                                                                 cycle                      236934.83
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.99
    Achieved Active Warps Per SM                                                      warp                          55.03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:56, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.56
    Elapsed Cycles                                                                   cycle                         244103
    Memory [%]                                                                           %                          92.35
    DRAM Throughput                                                                      %                           8.51
    Duration                                                                       usecond                         319.68
    L1/TEX Cache Throughput                                                              %                          95.03
    L2 Cache Throughput                                                                  %                          32.34
    SM Active Cycles                                                                 cycle                      237217.72
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.18
    Achieved Active Warps Per SM                                                      warp                          55.16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:56, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.20
    SM Frequency                                                             cycle/usecond                         758.05
    Elapsed Cycles                                                                   cycle                         242678
    Memory [%]                                                                           %                          92.89
    DRAM Throughput                                                                      %                           8.58
    Duration                                                                       usecond                         320.13
    L1/TEX Cache Throughput                                                              %                          95.09
    L2 Cache Throughput                                                                  %                          32.61
    SM Active Cycles                                                                 cycle                      237067.35
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.18
    Achieved Active Warps Per SM                                                      warp                          55.16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:57, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.85
    Elapsed Cycles                                                                   cycle                         243461
    Memory [%]                                                                           %                          92.59
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         318.72
    L1/TEX Cache Throughput                                                              %                          95.08
    L2 Cache Throughput                                                                  %                          32.40
    SM Active Cycles                                                                 cycle                      237087.73
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.18
    Achieved Active Warps Per SM                                                      warp                          55.15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:57, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.87
    Elapsed Cycles                                                                   cycle                         243444
    Memory [%]                                                                           %                          92.61
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.27
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.43
    SM Active Cycles                                                                 cycle                      236916.82
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.44
    Achieved Active Warps Per SM                                                      warp                          55.32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:57, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.68
    Elapsed Cycles                                                                   cycle                         242821
    Memory [%]                                                                           %                          92.83
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.37
    L1/TEX Cache Throughput                                                              %                          95.08
    L2 Cache Throughput                                                                  %                          32.52
    SM Active Cycles                                                                 cycle                      237076.26
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.00
    Achieved Active Warps Per SM                                                      warp                          55.04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:58, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.70
    Elapsed Cycles                                                                   cycle                         242678
    Memory [%]                                                                           %                          92.89
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.59
    L1/TEX Cache Throughput                                                              %                          95.12
    L2 Cache Throughput                                                                  %                          32.67
    SM Active Cycles                                                                 cycle                      236988.77
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.24
    Achieved Active Warps Per SM                                                      warp                          55.19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:58, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         765.61
    Elapsed Cycles                                                                   cycle                         243654
    Memory [%]                                                                           %                          92.51
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         318.24
    L1/TEX Cache Throughput                                                              %                          95.03
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                      237177.87
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.56
    Achieved Active Warps Per SM                                                      warp                          55.40
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:58, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.34
    Elapsed Cycles                                                                   cycle                         243394
    Memory [%]                                                                           %                          92.63
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.43
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.58
    SM Active Cycles                                                                 cycle                      236897.77
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.08
    Achieved Active Warps Per SM                                                      warp                          55.09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:59, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.27
    Elapsed Cycles                                                                   cycle                         243910
    Memory [%]                                                                           %                          92.41
    DRAM Throughput                                                                      %                           8.51
    Duration                                                                       usecond                         319.55
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.44
    SM Active Cycles                                                                 cycle                      237071.90
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.28
    Achieved Active Warps Per SM                                                      warp                          55.22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:59, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.47
    Elapsed Cycles                                                                   cycle                         243511
    Memory [%]                                                                           %                          92.58
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.53
    L1/TEX Cache Throughput                                                              %                          95.08
    L2 Cache Throughput                                                                  %                          32.57
    SM Active Cycles                                                                 cycle                      237087.31
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.33
    Achieved Active Warps Per SM                                                      warp                          55.25
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:10:59, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.83
    Elapsed Cycles                                                                   cycle                         243686
    Memory [%]                                                                           %                          92.49
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         320.70
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.28
    SM Active Cycles                                                                 cycle                      237073.09
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.16
    Achieved Active Warps Per SM                                                      warp                          55.14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:00, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.79
    Elapsed Cycles                                                                   cycle                         243126
    Memory [%]                                                                           %                          92.72
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.30
    L1/TEX Cache Throughput                                                              %                          95.13
    L2 Cache Throughput                                                                  %                          32.51
    SM Active Cycles                                                                 cycle                      236965.57
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.65
    Achieved Active Warps Per SM                                                      warp                          55.46
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:00, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.22
    Elapsed Cycles                                                                   cycle                         243062
    Memory [%]                                                                           %                          92.73
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.30
    L1/TEX Cache Throughput                                                              %                          95.04
    L2 Cache Throughput                                                                  %                          32.67
    SM Active Cycles                                                                 cycle                      237142.19
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.43
    Achieved Active Warps Per SM                                                      warp                          55.32
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:00, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         767.57
    Elapsed Cycles                                                                   cycle                         244350
    Memory [%]                                                                           %                          92.26
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         318.34
    L1/TEX Cache Throughput                                                              %                          95.14
    L2 Cache Throughput                                                                  %                          32.43
    SM Active Cycles                                                                 cycle                      236966.62
    Compute (SM) [%]                                                                     %                           5.82
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.85
    Achieved Active Warps Per SM                                                      warp                          54.94
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (85.8%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:00, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.95
    Elapsed Cycles                                                                   cycle                         243317
    Memory [%]                                                                           %                          92.64
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         319.33
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.52
    SM Active Cycles                                                                 cycle                      237125.60
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.15
    Achieved Active Warps Per SM                                                      warp                          55.14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:01, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.84
    Elapsed Cycles                                                                   cycle                         242770
    Memory [%]                                                                           %                          92.86
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         318.66
    L1/TEX Cache Throughput                                                              %                          95.13
    L2 Cache Throughput                                                                  %                          32.74
    SM Active Cycles                                                                 cycle                      236964.89
    Compute (SM) [%]                                                                     %                           5.87
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.64
    Achieved Active Warps Per SM                                                      warp                          55.45
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:01, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.59
    Elapsed Cycles                                                                   cycle                         243007
    Memory [%]                                                                           %                          92.75
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         319.49
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.62
    SM Active Cycles                                                                 cycle                      237072.72
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.19
    Achieved Active Warps Per SM                                                      warp                          55.16
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:01, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.79
    Elapsed Cycles                                                                   cycle                         242484
    Memory [%]                                                                           %                          92.97
    DRAM Throughput                                                                      %                           8.58
    Duration                                                                       usecond                         318.72
    L1/TEX Cache Throughput                                                              %                          95.14
    L2 Cache Throughput                                                                  %                          32.62
    SM Active Cycles                                                                 cycle                      236938.97
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.27
    Achieved Active Warps Per SM                                                      warp                          55.21
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:02, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.63
    Elapsed Cycles                                                                   cycle                         243218
    Memory [%]                                                                           %                          92.69
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         318.91
    L1/TEX Cache Throughput                                                              %                          95.01
    L2 Cache Throughput                                                                  %                          32.59
    SM Active Cycles                                                                 cycle                      237259.56
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.51
    Achieved Active Warps Per SM                                                      warp                          55.37
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:02, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.69
    Elapsed Cycles                                                                   cycle                         242208
    Memory [%]                                                                           %                          93.07
    DRAM Throughput                                                                      %                           8.59
    Duration                                                                       usecond                         318.82
    L1/TEX Cache Throughput                                                              %                          95.10
    L2 Cache Throughput                                                                  %                          32.58
    SM Active Cycles                                                                 cycle                      237026.44
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.50
    Achieved Active Warps Per SM                                                      warp                          55.36
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.5%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:02, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.00
    Elapsed Cycles                                                                   cycle                         243338
    Memory [%]                                                                           %                          92.63
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         318.91
    L1/TEX Cache Throughput                                                              %                          95.03
    L2 Cache Throughput                                                                  %                          32.40
    SM Active Cycles                                                                 cycle                      237192.61
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.11
    Achieved Active Warps Per SM                                                      warp                          55.11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:03, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         765.31
    Elapsed Cycles                                                                   cycle                         243436
    Memory [%]                                                                           %                          92.61
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.08
    L1/TEX Cache Throughput                                                              %                          95.10
    L2 Cache Throughput                                                                  %                          32.52
    SM Active Cycles                                                                 cycle                      237049.06
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.23
    Achieved Active Warps Per SM                                                      warp                          55.18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:03, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.27
    Elapsed Cycles                                                                   cycle                         243227
    Memory [%]                                                                           %                          92.67
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.07
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.38
    SM Active Cycles                                                                 cycle                      237113.92
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.61
    Achieved Active Warps Per SM                                                      warp                          55.43
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:03, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.07
    Elapsed Cycles                                                                   cycle                         243899
    Memory [%]                                                                           %                          92.43
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.12
    L2 Cache Throughput                                                                  %                          32.54
    SM Active Cycles                                                                 cycle                      236982.50
    Compute (SM) [%]                                                                     %                           5.83
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.41
    Achieved Active Warps Per SM                                                      warp                          55.31
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.4%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:03, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.74
    Elapsed Cycles                                                                   cycle                         243496
    Memory [%]                                                                           %                          92.57
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         319.65
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.45
    SM Active Cycles                                                                 cycle                      237132.34
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.15
    Achieved Active Warps Per SM                                                      warp                          55.14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:04, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         765.09
    Elapsed Cycles                                                                   cycle                         244222
    Memory [%]                                                                           %                          92.30
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.13
    L2 Cache Throughput                                                                  %                          32.44
    SM Active Cycles                                                                 cycle                      236940.75
    Compute (SM) [%]                                                                     %                           5.83
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.13
    Achieved Active Warps Per SM                                                      warp                          55.12
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:04, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.85
    Elapsed Cycles                                                                   cycle                         242844
    Memory [%]                                                                           %                          92.83
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         319.17
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.60
    SM Active Cycles                                                                 cycle                      237149.06
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.60
    Achieved Active Warps Per SM                                                      warp                          55.42
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:04, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.78
    Elapsed Cycles                                                                   cycle                         242509
    Memory [%]                                                                           %                          92.97
    DRAM Throughput                                                                      %                           8.58
    Duration                                                                       usecond                         318.34
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.75
    SM Active Cycles                                                                 cycle                      236883.15
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.00
    Achieved Active Warps Per SM                                                      warp                          55.04
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:05, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.28
    Elapsed Cycles                                                                   cycle                         242541
    Memory [%]                                                                           %                          92.94
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         319.42
    L1/TEX Cache Throughput                                                              %                          95.04
    L2 Cache Throughput                                                                  %                          32.70
    SM Active Cycles                                                                 cycle                      237170.83
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.34
    Achieved Active Warps Per SM                                                      warp                          55.26
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:05, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.49
    Elapsed Cycles                                                                   cycle                         242758
    Memory [%]                                                                           %                          92.87
    DRAM Throughput                                                                      %                           8.57
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.12
    L2 Cache Throughput                                                                  %                          32.50
    SM Active Cycles                                                                 cycle                      237002.58
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.28
    Achieved Active Warps Per SM                                                      warp                          55.22
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.3%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:05, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.61
    Elapsed Cycles                                                                   cycle                         243429
    Memory [%]                                                                           %                          92.61
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.02
    L2 Cache Throughput                                                                  %                          32.59
    SM Active Cycles                                                                 cycle                      237233.04
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.08
    Achieved Active Warps Per SM                                                      warp                          55.09
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:05, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.50
    Elapsed Cycles                                                                   cycle                         243642
    Memory [%]                                                                           %                          92.53
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.10
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.45
    SM Active Cycles                                                                 cycle                      236876.80
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.17
    Achieved Active Warps Per SM                                                      warp                          55.15
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:06, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         759.34
    Elapsed Cycles                                                                   cycle                         242388
    Memory [%]                                                                           %                          92.99
    DRAM Throughput                                                                      %                           8.58
    Duration                                                                       usecond                         319.20
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.61
    SM Active Cycles                                                                 cycle                      237115.51
    Compute (SM) [%]                                                                     %                           5.88
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.99
    Achieved Active Warps Per SM                                                      warp                          55.03
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:06, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.84
    Elapsed Cycles                                                                   cycle                         243162
    Memory [%]                                                                           %                          92.72
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.75
    L1/TEX Cache Throughput                                                              %                          95.17
    L2 Cache Throughput                                                                  %                          32.53
    SM Active Cycles                                                                 cycle                      236886.78
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.10
    Achieved Active Warps Per SM                                                      warp                          55.10
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:06, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.84
    Elapsed Cycles                                                                   cycle                         243507
    Memory [%]                                                                           %                          92.57
    DRAM Throughput                                                                      %                           8.53
    Duration                                                                       usecond                         318.78
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.51
    SM Active Cycles                                                                 cycle                      237092.56
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.58
    Achieved Active Warps Per SM                                                      warp                          54.77
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (85.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:07, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         763.38
    Elapsed Cycles                                                                   cycle                         243506
    Memory [%]                                                                           %                          92.58
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         318.98
    L1/TEX Cache Throughput                                                              %                          95.14
    L2 Cache Throughput                                                                  %                          32.43
    SM Active Cycles                                                                 cycle                      236953.94
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.11
    Achieved Active Warps Per SM                                                      warp                          55.11
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.1%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:07, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         760.42
    Elapsed Cycles                                                                   cycle                         242950
    Memory [%]                                                                           %                          92.78
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.49
    L1/TEX Cache Throughput                                                              %                          95.04
    L2 Cache Throughput                                                                  %                          32.51
    SM Active Cycles                                                                 cycle                      237188.61
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.16
    Achieved Active Warps Per SM                                                      warp                          55.14
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:07, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.49
    Elapsed Cycles                                                                   cycle                         243125
    Memory [%]                                                                           %                          92.74
    DRAM Throughput                                                                      %                           8.56
    Duration                                                                       usecond                         318.85
    L1/TEX Cache Throughput                                                              %                          95.11
    L2 Cache Throughput                                                                  %                          32.55
    SM Active Cycles                                                                 cycle                      237045.05
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.56
    Achieved Active Warps Per SM                                                      warp                          55.40
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.6%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:08, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         765.65
    Elapsed Cycles                                                                   cycle                         244205
    Memory [%]                                                                           %                          92.29
    DRAM Throughput                                                                      %                           8.50
    Duration                                                                       usecond                         318.94
    L1/TEX Cache Throughput                                                              %                          95.06
    L2 Cache Throughput                                                                  %                          32.44
    SM Active Cycles                                                                 cycle                      237073.37
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.23
    Achieved Active Warps Per SM                                                      warp                          55.19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:08, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.22
    SM Frequency                                                             cycle/usecond                         767.16
    Elapsed Cycles                                                                   cycle                         243460
    Memory [%]                                                                           %                          92.59
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         317.34
    L1/TEX Cache Throughput                                                              %                          95.14
    L2 Cache Throughput                                                                  %                          32.46
    SM Active Cycles                                                                 cycle                      236922.52
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.02
    Achieved Active Warps Per SM                                                      warp                          55.05
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:08, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.73
    Elapsed Cycles                                                                   cycle                         243054
    Memory [%]                                                                           %                          92.73
    DRAM Throughput                                                                      %                           8.54
    Duration                                                                       usecond                         319.07
    L1/TEX Cache Throughput                                                              %                          95.07
    L2 Cache Throughput                                                                  %                          32.53
    SM Active Cycles                                                                 cycle                      237074.23
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.22
    Achieved Active Warps Per SM                                                      warp                          55.18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:08, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         762.38
    Elapsed Cycles                                                                   cycle                         243502
    Memory [%]                                                                           %                          92.57
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.39
    L1/TEX Cache Throughput                                                              %                          95.15
    L2 Cache Throughput                                                                  %                          32.40
    SM Active Cycles                                                                 cycle                      236895.25
    Compute (SM) [%]                                                                     %                           5.85
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.22
    Achieved Active Warps Per SM                                                      warp                          55.18
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:09, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         764.54
    Elapsed Cycles                                                                   cycle                         243849
    Memory [%]                                                                           %                          92.45
    DRAM Throughput                                                                      %                           8.52
    Duration                                                                       usecond                         318.94
    L1/TEX Cache Throughput                                                              %                          95.05
    L2 Cache Throughput                                                                  %                          32.47
    SM Active Cycles                                                                 cycle                      237168.38
    Compute (SM) [%]                                                                     %                           5.84
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          85.96
    Achieved Active Warps Per SM                                                      warp                          55.01
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.0%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

  jacobi(double ***, double ***, double ***, int, int, double, double), 2022-Jan-20 21:11:09, Context 1, Stream 7
    Section: GPU Speed Of Light Throughput
    ---------------------------------------------------------------------- --------------- ------------------------------
    DRAM Frequency                                                           cycle/nsecond                           1.21
    SM Frequency                                                             cycle/usecond                         761.81
    Elapsed Cycles                                                                   cycle                         243197
    Memory [%]                                                                           %                          92.70
    DRAM Throughput                                                                      %                           8.55
    Duration                                                                       usecond                         319.23
    L1/TEX Cache Throughput                                                              %                          95.16
    L2 Cache Throughput                                                                  %                          32.66
    SM Active Cycles                                                                 cycle                      236910.28
    Compute (SM) [%]                                                                     %                           5.86
    ---------------------------------------------------------------------- --------------- ------------------------------
    INF   The kernel is utilizing greater than 80.0% of the available compute or memory performance of the device. To   
          further improve performance, work will likely need to be shifted from the most utilized to another unit.      
          Start by analyzing workloads in the Memory Workload Analysis section.                                         

    Section: Launch Statistics
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Size                                                                                                        512
    Function Cache Configuration                                                                  cudaFuncCachePreferNone
    Grid Size                                                                                                        4096
    Registers Per Thread                                                   register/thread                             28
    Shared Memory Configuration Size                                                 Kbyte                          16.38
    Driver Shared Memory Per Block                                             Kbyte/block                           1.02
    Dynamic Shared Memory Per Block                                             byte/block                              0
    Static Shared Memory Per Block                                              byte/block                              0
    Threads                                                                         thread                        2097152
    Waves Per SM                                                                                                     9.48
    ---------------------------------------------------------------------- --------------- ------------------------------

    Section: Occupancy
    ---------------------------------------------------------------------- --------------- ------------------------------
    Block Limit SM                                                                   block                             32
    Block Limit Registers                                                            block                              4
    Block Limit Shared Mem                                                           block                            164
    Block Limit Warps                                                                block                              4
    Theoretical Active Warps per SM                                                   warp                             64
    Theoretical Occupancy                                                                %                            100
    Achieved Occupancy                                                                   %                          86.24
    Achieved Active Warps Per SM                                                      warp                          55.19
    ---------------------------------------------------------------------- --------------- ------------------------------
    WRN   This kernel's theoretical occupancy is not impacted by any block limit. The difference between calculated     
          theoretical (100.0%) and measured achieved occupancy (86.2%) can be the result of warp scheduling overheads   
          or workload imbalances during the kernel execution. Load imbalances can occur between warps within a block    
          as well as across blocks of the same kernel. See the CUDA Best Practices Guide                                
          (https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#occupancy) for more details on           
          optimizing occupancy.                                                                                         

128 0.033184
